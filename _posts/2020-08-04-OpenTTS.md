---
title:  "Pytorch POC #2: OpenTTS"
date: 2020-08-06
categories: [ Pytorch, "Pre-trained Model", "Speech Synthesis", "Supervised Learning"]
image: "/assets/images/06.08.2020_17.35.25_REC.png"
visit: http://dlc.barco.com:5500/
tags: [featured]
---

| Git Repo                                                                                                                                         | Status                                                                                                                                                                | Progress                                                                                                                    | Comments                                                     |
|--------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------|
| [![OpenTTS](https://img.shields.io/badge/OpenTTS-gray?logo=pytorch)](https://git.barco.com/users/wjlee/repos/opentts/browse) | [![status](https://tailab.barco.com:9443/deeplearningcomputing/opentts/badges/master/pipeline.svg)](https://tailab.barco.com:9443/deeplearningcomputing/opentts/pipelines) | [![progress](https://img.shields.io/badge/OpenTTS-POC-red)](http://dlc.barco.com:5500/) | Pytorch POC #2 |
| [![mozillatts](https://img.shields.io/badge/project-mozillatts-red)](https://git.barco.com/users/wjlee/repos/TTS/browse) | [![status](https://tailab.barco.com:9443/deeplearningcomputing/TTS/badges/master/pipeline.svg)](https://tailab.barco.com:9443/deeplearningcomputing/TTS/pipelines) | [![progress](https://img.shields.io/badge/mozillatts-POC-red)](http://dlc.barco.com:5002/) | Pytorch POC #3 |
| [![MaryTTS](https://img.shields.io/badge/MaryTTS-gray?logo=pytorch)](https://git.barco.com/users/wjlee/repos/docker-marytts/browse) | [![status](https://tailab.barco.com:9443/deeplearningcomputing/docker-marytts/badges/master/pipeline.svg)](https://tailab.barco.com:9443/deeplearningcomputing/docker-marytts/pipelines) | [![progress](https://img.shields.io/badge/marytts-POC-red)](http://dlc.barco.com:15195/) | Pytorch POC #4 |

[![](https://rebrand.ly/dlc_png_url)](https://rebrand.ly/dlc_uml_url)

Based on last time keyword spotting topics on Chimay, I even mention items about TTS (text-to-speech) and showed [POCs](https://wiki.barco.com/display/wovcs/Keyword+spotting). Here I adopt [Opentts](https://github.com/synesthesiam/opentts) to create a API server for speech and later ultrasound generation from Web.

[![Opentts]({{site.url}}{{site.baseurl}}/assets/images/06.08.2020_17.35.25_REC.png)](http://dlc.barco.com:5500)


In [live opentts demo site](http://dlc.barco.com:5500), you can check the conventional (non-deep learning) speech synthesis (marytts, nanotts) and deep-learning ones (Mozillatts with Tacotron and Tacotron2). Deep-learing ones provide a beeter speech quality. A public MOS test results as below also show similar conclusions.

![MOS]({{site.url}}{{site.baseurl}}/assets/images/6428f980e9ec751c248e591460895f7881aec0c6.png)

Demo wave file as 

![Demo wave]({{site.url}}{{site.baseurl}}/assets/images/11082020-130135-REC.gif)


Swagger API also includes the following:

[![Opentts swagger]({{site.url}}{{site.baseurl}}/assets/images/10.08.2020_11.16.07_REC.png)](http://dlc.barco.com:5500/api/)

The following diagram is from mozzila project. It shows the whole picture of nature lanaugege iteration with end users. But, of course, it will be a long way to go.

![](https://lh6.googleusercontent.com/Q6m5nMv5m0fMTPyqKhtsBmkjHGQaRmriqadxUXUhmua5rupIndMMDGcDtn2IJwa8042UgpcMrbPYTG4PNSvtqJmZi5hWEWjSqCOyRmPHnIz7vpNlgIzyjlIhV8QdxRHdF1fcelUy)

## References
* [Chimay Architecture for Keyword spotting](https://wiki.barco.com/display/wovcs/Keyword+spotting)
* [Paper with code- speech synthesis](https://paperswithcode.com/task/speech-synthesis)
* [Diagram of mozillatts- Tacotron and Tacotron2](https://github.com/mozilla/TTS/wiki)
* [TSS systems and models](https://www.evernote.com/shard/s146/client/snv?noteGuid=9544e7e9-d372-4610-a7b7-3ddcb63d5dac&noteKey=d01d33837dab625229dec3cfb4cfb887&sn=https%3A%2F%2Fwww.evernote.com%2Fshard%2Fs146%2Fsh%2F9544e7e9-d372-4610-a7b7-3ddcb63d5dac%2Fd01d33837dab625229dec3cfb4cfb887&title=TSS%2Bsystems%2Band%2Bmodels)
* [How to build a voice assistant with open source Rasa and Mozilla tools](https://blog.rasa.com/how-to-build-a-voice-assistant-with-open-source-rasa-and-mozilla-tools/)
* [The CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)
* [Build End-To-End TTS Tacotron: Griffin Lim 信号估计算法](https://zhuanlan.zhihu.com/p/25002923)
* [Mozilla 研究：有些機器合成語音已經比真人聲音更悅耳](https://medium.com/@moz2000tw/mozilla-%E7%A0%94%E7%A9%B6-%E6%9C%89%E4%BA%9B%E6%A9%9F%E5%99%A8%E5%90%88%E6%88%90%E8%AA%9E%E9%9F%B3%E5%B7%B2%E7%B6%93%E6%AF%94%E7%9C%9F%E4%BA%BA%E8%81%B2%E9%9F%B3%E6%9B%B4%E6%82%85%E8%80%B3-ad795fd566b7)
